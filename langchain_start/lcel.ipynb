{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "LCEL Study\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"LCEL Study\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response  # 스트리밍 출력\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"대한민국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"미국\")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'으로 설정합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능 모델의 학습 원리는 데이터를 입력으로 받아들이고 이를 분석하여 패턴이나 규칙을 학습하는 과정입니다. 이 학습 과정은 크게 입력층, 은닉층, 출력층으로 구성된 신경망을 사용하여 이루어집니다.\\n\\n먼저 모델은 입력층에서 주어진 데이터를 받아들이고, 은닉층에서 이 데이터를 처리하여 중요한 특징이나 패턴을 추출합니다. 그리고 출력층에서는 이러한 은닉층의 처리 결과를 바탕으로 원하는 결과를 도출합니다.\\n\\n학습 과정에서 모델은 입력 데이터와 이에 대응하는 정답 데이터를 사용하여 오차를 계산하고, 이 오차를 최소화하는 방향으로 모델을 업데이트합니다. 이러한 과정을 반복하면서 모델은 점차 정확한 예측을 할 수 있도록 학습하게 됩니다.', response_metadata={'token_usage': {'completion_tokens': 295, 'prompt_tokens': 33, 'total_tokens': 328}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0c3f515b-407e-417f-a32e-cb1dea560032-0', usage_metadata={'input_tokens': 33, 'output_tokens': 295, 'total_tokens': 328})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인공지능 모델의 학습 원리는 데이터를 입력으로 받아들이고 이를 통해 패턴을 학습하는 과정입니다. \\n\\n먼저 모델은 입력 데이터를 받아들여 이를 처리하고 결과를 출력합니다. 이때 모델은 예측한 결과와 실제 정답을 비교하여 오차를 계산합니다. \\n\\n그 다음 모델은 이 오차를 최소화하는 방향으로 가중치를 업데이트하고 다시 입력 데이터를 받아들여 결과를 출력합니다. 이러한 과정을 반복하면서 모델은 데이터의 패턴을 학습하고 정확한 예측을 할 수 있게 됩니다. \\n\\n이렇게 학습된 모델은 새로운 데이터를 입력으로 받아들여 예측을 수행하고 이를 통해 다양한 문제를 해결하거나 판단을 할 수 있습니다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "chain.invoke(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 이를 분석하고 학습하여 원하는 결과를 도출하는 과정입니다. 이때, 모델은 입력데이터와 그에 대한 정답 레이블을 학습하여 최적의 매개변수를 찾아내는 것이 목표입니다.\n",
      "\n",
      "일반적으로, 인공지능 모델은 입력 데이터를 받아들이기 위한 입력층, 데이터를 처리하고 분석하는 은닉층, 그리고 결과를 출력하는 출력층으로 구성되어 있습니다. 학습 과정에서 모델은 입력 데이터를 받아들이고, 이를 처리하여 출력을 생성합니다. 이때, 모델이 생성한 출력과 실제 정답과의 차이를 계산하여 이 차이를 최소화하도록 모델을 업데이트 하여 학습을 진행합니다.\n",
      "\n",
      "이러한 과정을 반복하여 모델은 점차적으로 입력 데이터에 대한 패턴을 학습하고, 새로운 데이터가 주어졌을 때 정확한 결과를 예측할 수 있도록 학습됩니다. 이러한 원리를 통해 인공지능 모델은 데이터를 분석하고 패턴을 학습하여 다양한 작업을 수행할 수 있게 됩니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "당신은 Langchain에 대해 가르치는 강사입니다. 질문에 대한 답변을 한글로 예시와 함께 알려주세요.\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 챗모델을 초기화합니다.\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# 문자열 출력 파서를 초기화합니다.\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCEL(LangChain Expression Language)은 LangChain에서 사용하는 표현 언어로, 다양한 데이터 소스와 상호작용하고 복잡한 작업을 수행할 수 있도록 도와줍니다. LCEL은 주로 데이터 처리, 변환, 쿼리, 그리고 API 호출을 쉽게 만들 수 있는 기능을 제공합니다.\n",
      "\n",
      "### LCEL의 주요 특징\n",
      "\n",
      "1. **가독성**: LCEL은 자연어에 가까운 문법을 사용하여 코드의 가독성을 높입니다. 이를 통해 비개발자도 쉽게 이해하고 사용할 수 있습니다.\n",
      "\n",
      "2. **유연성**: 다양한 데이터 소스와 통합할 수 있는 유연성을 제공합니다. 예를 들어, 데이터베이스, API, 파일 시스템 등 여러 소스에서 데이터를 가져오고 처리할 수 있습니다.\n",
      "\n",
      "3. **모듈성**: LCEL은 다양한 기능을 모듈화하여 필요에 따라 사용할 수 있습니다. 각 기능은 독립적으로 작동하며, 필요할 때만 불러와서 사용할 수 있습니다.\n",
      "\n",
      "### 예시\n",
      "\n",
      "아래는 LCEL을 사용하여 간단한 데이터 쿼리를 작성하는 예시입니다.\n",
      "\n",
      "```lcel\n",
      "SELECT name, age FROM users WHERE age > 18\n",
      "```\n",
      "\n",
      "위의 쿼리는 `users` 테이블에서 나이가 18세 이상인 사용자들의 이름과 나이를 선택하는 예입니다. LCEL의 문법을 사용하면 SQL과 유사하게 데이터를 쿼리할 수 있습니다.\n",
      "\n",
      "또 다른 예로, API 호출을 통해 데이터를 가져오는 경우:\n",
      "\n",
      "```lcel\n",
      "GET https://api.example.com/data?query=searchTerm\n",
      "```\n",
      "\n",
      "위의 예시는 `https://api.example.com/data` 엔드포인트에서 `searchTerm`을 쿼리 파라미터로 사용하여 데이터를 가져오는 API 호출을 나타냅니다.\n",
      "\n",
      "### 결론\n",
      "\n",
      "LCEL은 데이터 처리와 API 통합을 간편하게 만들어주는 강력한 도구입니다. 이를 통해 개발자와 데이터 분석가는 보다 효율적으로 작업할 수 있으며, 복잡한 쿼리나 데이터 변환 작업도 쉽게 수행할 수 있습니다."
     ]
    }
   ],
   "source": [
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"LCEL에 대해 자세하게 알려주세요\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
